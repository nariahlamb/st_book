#!/usr/bin/env python3\n\"\"\"\nLLM-based角色提取器 - 使用大语言模型智能分析角色信息\n\"\"\"\n\nimport os\nimport json\nimport time\nimport asyncio\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Tuple\nfrom openai import AsyncOpenAI\nfrom project_config import get_config\n\nclass LLMCharacterExtractor:\n    \"\"\"使用LLM的智能角色提取器\"\"\"\n    \n    def __init__(self):\n        self.config = get_config()\n        # 从配置加载路径\n        self.chunks_dir = Path(self.config.get(\"output.chunk_dir\", \"chunks\"))\n        self.output_dir = Path(self.config.get(\"output.character_responses_dir\", \"character_responses\"))\n        self.raw_dir = Path(self.config.get(\"output.character_responses_raw_dir\", \"character_responses_raw\"))\n        self.bad_dir = Path(self.config.get(\"output.character_responses_bad_dir\", \"character_responses_bad\"))\n\n        # 创建输出目录\n        for dir_path in [self.output_dir, self.raw_dir, self.bad_dir]:\n            dir_path.mkdir(exist_ok=True)\n\n        # 初始化OpenAI客户端\n        api_config = self.config.get_api_config()\n        model_config = self.config.get_model_config()\n        api_key = api_config.get(\"api_key\")\n        if not api_key:\n            raise ValueError(\"❌ 找不到 API 金鑰，請在 config.yaml 中設定 'api.api_key'\")\n\n        self.client = AsyncOpenAI(\n            api_key=api_key,\n            base_url=api_config.get(\"api_base\"),\n            timeout=int(model_config.get(\"timeout\", 300))\n        )\n\n        # 使用新的配置系统\n        model_config = self.config.get_model_config()\n        api_config = self.config.get_api_config()\n\n        self.model = model_config.get(\"extraction_model\", \"gemini-2.5-flash\")\n        self.extraction_temperature = model_config.get(\"extraction_temperature\", 0.3)\n        self.max_tokens = int(model_config.get(\"max_tokens\", 60000))\n\n        # 性能配置\n        self.max_concurrent = int(self.config.get(\"performance.max_concurrent\", 1))\n        self.retry_limit = int(self.config.get(\"performance.retry_limit\", 5))\n        self.retry_delay = int(self.config.get(\"performance.retry_delay\", 10))\n        self.rate_limit_delay = int(self.config.get(\"performance.rate_limit_delay\", 5))\n\n    def get_extraction_prompt(self) -> str:\n        \"\"\"获取角色提取的提示词\"\"\"\n        return \"\"\"\n你是一个专业的小说角色分析师。请从给定的文本中提取所有出现的角色信息。\n\n要求：\n1. 提取所有在文本中出现的角色（包括主角、配角、路人等）\n2. 对每个角色，提供以下信息：\n   - name: 角色姓名（必须）\n   - aliases: 别名、称号、外号等（数组格式）\n   - description: 角色描述（外貌、性格、背景等）\n   - relationships: 与其他角色的关系\n   - abilities: 能力、技能、特长\n   - dialogues: 角色的典型对话（最多3句）\n   - scenes: 角色出现的场景描述\n\n3. 输出格式必须是有效的JSON数组，每个元素是一个角色对象\n4. 如果文本中没有明确的角色，返回空数组 []\n5. 确保所有字符串都正确转义，避免JSON解析错误\n\n示例输出格式：\n[\n  {\n    \"name\": \"张三\",\n    \"aliases\": [\"小张\", \"张师傅\"],\n    \"description\": \"一个中年男子，身材魁梧，性格豪爽\",\n    \"relationships\": \"李四的好友，王五的师父\",\n    \"abilities\": \"武功高强，擅长剑法\",\n    \"dialogues\": [\"哈哈，好久不见！\", \"这剑法还需要多练习\"],\n    \"scenes\": \"在酒楼中与朋友畅饮，在练武场指导弟子\"\n  }\n]\n\n请分析以下文本：\n\"\"\"\n\n    async def extract_characters_from_chunk(self, chunk_file: Path) -> Optional[List[Dict]]:\n        \"\"\"从单个文本块提取角色信息\"\"\"\n        try:\n            # 读取文本块\n            with open(chunk_file, 'r', encoding='utf-8') as f:\n                text = f.read().strip()\n            \n            if not text:\n                print(f\"[WARNING] 空文本块: {chunk_file.name}\")\n                return []\n\n            # 构建完整的提示\n            full_prompt = self.get_extraction_prompt() + \"\\n\\n\" + text\n\n            # 调用LLM进行提取\n            for attempt in range(self.retry_limit):\n                try:\n                    response = await self.client.chat.completions.create(\n                        model=self.model,\n                        messages=[\n                            {\"role\": \"user\", \"content\": full_prompt}\n                        ],\n                        temperature=self.extraction_temperature,\n                        max_tokens=self.max_tokens\n                    )\n                    \n                    raw_content = response.choices[0].message.content.strip()\n                    \n                    # 保存原始响应\n                    raw_file = self.raw_dir / f\"{chunk_file.stem}.txt\"\n                    with open(raw_file, 'w', encoding='utf-8') as f:\n                        f.write(raw_content)\n                    \n                    # 解析JSON响应\n                    try:\n                        characters = json.loads(raw_content)\n                        if isinstance(characters, list):\n                            print(f\"[SUCCESS] {chunk_file.name}: 提取到 {len(characters)} 个角色\")\n                            return characters\n                        else:\n                            print(f\"[ERROR] {chunk_file.name}: 响应不是数组格式\")\n                            return []\n                    except json.JSONDecodeError as e:\n                        print(f\"[ERROR] {chunk_file.name}: JSON解析失败 - {e}\")\n                        # 保存解析失败的响应\n                        bad_file = self.bad_dir / f\"{chunk_file.stem}.txt\"\n                        with open(bad_file, 'w', encoding='utf-8') as f:\n                            f.write(raw_content)\n                        return []\n                    \n                except Exception as e:\n                    print(f\"[ERROR] {chunk_file.name}: API调用失败 (尝试 {attempt + 1}/{self.retry_limit}) - {e}\")\n                    if attempt < self.retry_limit - 1:\n                        await asyncio.sleep(self.retry_delay)\n                    else:\n                        return []\n            \n            return []\n            \n        except Exception as e:\n            print(f\"[ERROR] 处理文件 {chunk_file.name} 时发生错误: {e}\")\n            return []\n\n    async def process_chunk_batch(self, chunk_files: List[Path]) -> None:\n        \"\"\"批量处理文本块\"\"\"\n        semaphore = asyncio.Semaphore(self.max_concurrent)\n        \n        async def process_single_chunk(chunk_file: Path):\n            async with semaphore:\n                characters = await self.extract_characters_from_chunk(chunk_file)\n                if characters:\n                    # 保存提取结果\n                    output_file = self.output_dir / f\"{chunk_file.stem}.json\"\n                    with open(output_file, 'w', encoding='utf-8') as f:\n                        json.dump(characters, f, ensure_ascii=False, indent=2)\n                \n                # 添加速率限制延迟\n                await asyncio.sleep(self.rate_limit_delay)\n        \n        # 并发处理所有文本块\n        tasks = [process_single_chunk(chunk_file) for chunk_file in chunk_files]\n        await asyncio.gather(*tasks)\n\n    async def extract_all_characters(self) -> None:\n        \"\"\"提取所有文本块中的角色信息\"\"\"\n        print(\"开始从文本块中提取角色信息...\")\n        \n        # 获取所有文本块文件\n        chunk_files = sorted(self.chunks_dir.glob(\"chunk_*.txt\"))\n        \n        if not chunk_files:\n            print(f\"[ERROR] 在 {self.chunks_dir} 中没有找到文本块文件\")\n            print(\"请先运行文本分割步骤\")\n            return\n        \n        print(f\"找到 {len(chunk_files)} 个文本块文件\")\n        print(f\"使用模型: {self.model}\")\n        print(f\"最大并发数: {self.max_concurrent}\")\n        print(f\"输出目录: {self.output_dir}\")\n        \n        start_time = time.time()\n        \n        # 批量处理文本块\n        await self.process_chunk_batch(chunk_files)\n        \n        end_time = time.time()\n        elapsed_time = end_time - start_time\n        \n        # 统计结果\n        output_files = list(self.output_dir.glob(\"*.json\"))\n        total_characters = 0\n        \n        for output_file in output_files:\n            try:\n                with open(output_file, 'r', encoding='utf-8') as f:\n                    characters = json.load(f)\n                    total_characters += len(characters)\n            except:\n                pass\n        \n        print(f\"\\n=== 提取完成 ===\")\n        print(f\"处理时间: {elapsed_time:.1f} 秒\")\n        print(f\"成功处理: {len(output_files)}/{len(chunk_files)} 个文本块\")\n        print(f\"提取角色总数: {total_characters} 个\")\n        print(f\"平均每块: {total_characters/len(output_files):.1f} 个角色\" if output_files else \"平均每块: 0 个角色\")\n        print(f\"输出目录: {self.output_dir}\")\n\n    async def process_all_chunks(self):\n        \"\"\"处理所有文本块（兼容旧接口）\"\"\"\n        await self.extract_all_characters()\n\nif __name__ == \"__main__\":\n    async def main():\n        extractor = LLMCharacterExtractor()\n        await extractor.extract_all_characters()\n    \n    asyncio.run(main())"