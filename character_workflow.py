#!/usr/bin/env python3
"""
è§’è‰²å·¥ä½œæµç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†è§’è‰²æå–å’Œåˆå¹¶æµç¨‹
"""

import sys
import json
from pathlib import Path
from typing import Dict, List
import time

import shutil

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("""
è§’è‰²å·¥ä½œæµç®¡ç†å™¨ - ä½¿ç”¨è¯´æ˜

**è§’è‰²å¡åˆ¶ä½œ**
  python character_workflow.py auto        - [æ¨è] ä¸€é”®å…¨è‡ªåŠ¨åˆ¶å¡ (æ¸…ç†å¹¶å®Œæ•´è¿è¡Œ)
  python character_workflow.py full        - æ‰§è¡Œå®Œæ•´æµç¨‹ (ä¸æ¸…ç†)
  python character_workflow.py split       - åˆ†å‰²å°è¯´æ–‡æœ¬ä¸ºæ–‡æœ¬å—
  python character_workflow.py extract     - ä»æ–‡æœ¬å—æå–è§’è‰²ä¿¡æ¯
  python character_workflow.py merge       - åˆå¹¶é‡å¤çš„è§’è‰²æ•°æ®
  python character_workflow.py filter      - ç­›é€‰è§’è‰²ï¼Œä¿ç•™å‰50ä¸ªæœ€å¤§çš„æ–‡ä»¶
  python character_workflow.py create      - ä»åˆå¹¶åçš„æ•°æ®åˆ›å»ºè§’è‰²å¡

**ä¸–ç•Œä¹¦åˆ¶ä½œ**
  python character_workflow.py wb-auto      - [æ¨è] ä¸€é”®å…¨è‡ªåŠ¨ç”Ÿæˆä¸–ç•Œä¹¦ (æ¸…ç†å¹¶å®Œæ•´è¿è¡Œ)
  python character_workflow.py wb-extract   - [æ­¥éª¤1] æå–ä¸–ç•Œä¹¦åŸå§‹æ¡ç›®
  python character_workflow.py wb-generate  - [æ­¥éª¤2] å°†åŸå§‹æ¡ç›®å‡åä¸ºç»“æ„åŒ–ä¸–ç•Œä¹¦

**é€šç”¨å‘½ä»¤**
  python character_workflow.py status      - æ˜¾ç¤ºå·¥ä½œæµçŠ¶æ€
  python character_workflow.py clean       - æ¸…ç†æ‰€æœ‰ä¸­é—´åŠè¾“å‡ºæ–‡ä»¶
  python character_workflow.py help        - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
""")

def show_status():
    """æ˜¾ç¤ºå·¥ä½œæµçŠ¶æ€"""
    print("="*60)
    print("è§’è‰²å·¥ä½œæµçŠ¶æ€")
    print("="*60)
    
    # æ£€æŸ¥å„ä¸ªç›®å½•çš„çŠ¶æ€
    directories = {
        "æ–‡æœ¬åˆ†å— (chunks)": Path("chunks"),
        "åŸå§‹è§’è‰²æ•°æ® (character_responses)": Path("character_responses"),
        "åˆå¹¶è§’è‰²æ•°æ® (roles_json)": Path("roles_json"),
        "è§’è‰²å¡ (cards)": Path("cards")
    }
    
    for desc, dir_path in directories.items():
        if dir_path.exists():
            if desc.startswith("æ–‡æœ¬åˆ†å—"):
                files = list(dir_path.glob("chunk_*.txt"))
            else:
                files = list(dir_path.glob("*.json"))
                # æ’é™¤ç»Ÿè®¡æ–‡ä»¶
                files = [f for f in files if f.name not in ['character_stats.json']]
            
            print(f"{desc}: {len(files)} ä¸ªæ–‡ä»¶")
            
            # æ˜¾ç¤ºæœ€æ–°æ–‡ä»¶çš„æ—¶é—´
            if files:
                latest_file = max(files, key=lambda f: f.stat().st_mtime)
                mtime = time.ctime(latest_file.stat().st_mtime)
                print(f"  æœ€æ–°æ–‡ä»¶: {latest_file.name} ({mtime})")
        else:
            print(f"{desc}: ç›®å½•ä¸å­˜åœ¨")
    
    # æ£€æŸ¥å·¥ä½œæµå®Œæˆåº¦
    print(f"\nå·¥ä½œæµå®Œæˆåº¦:")

    novel_exist = Path("a.txt").exists()
    chunks_exist = Path("chunks").exists() and list(Path("chunks").glob("chunk_*.txt"))
    extracted_exist = Path("character_responses").exists() and list(Path("character_responses").glob("*.json"))
    merged_exist = Path("roles_json").exists() and list(Path("roles_json").glob("*.json"))
    cards_exist = Path("cards").exists() and list(Path("cards").glob("*.json"))

    steps = [
        ("0. å°è¯´æ–‡ä»¶", novel_exist),
        ("1. æ–‡æœ¬åˆ†å—", chunks_exist),
        ("2. è§’è‰²æå–", extracted_exist),
        ("3. è§’è‰²åˆå¹¶", merged_exist),
        ("4. è§’è‰²å¡ç”Ÿæˆ", cards_exist)
    ]

    for step_name, completed in steps:
        status = "[å®Œæˆ]" if completed else "[æœªå®Œæˆ]"
        print(f"  {step_name}: {status}")

    # æ¨èä¸‹ä¸€æ­¥æ“ä½œ
    print(f"\næ¨èæ“ä½œ:")
    if not novel_exist:
        print("  éœ€è¦å…ˆå‡†å¤‡å°è¯´æ–‡ä»¶ a.txt")
    elif not chunks_exist:
        print("  è¿è¡Œ: python character_workflow.py split")
    elif not extracted_exist:
        print("  è¿è¡Œ: python character_workflow.py extract")
    elif not merged_exist:
        print("  è¿è¡Œ: python character_workflow.py merge")
    elif not cards_exist:
        print("  è¿è¡Œ: python character_workflow.py create")
    else:
        print("  å·¥ä½œæµå·²å®Œæˆï¼å¯ä»¥ä½¿ç”¨ç”Ÿæˆçš„è§’è‰²å¡")

def split_text():
    """åˆ†å‰²æ–‡æœ¬"""
    print("å¼€å§‹æ–‡æœ¬åˆ†å‰²...")
    try:
        from text_splitter import TextSplitter

        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        input_file = "a.txt"
        if not Path(input_file).exists():
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_file}")
            print("è¯·å°†å°è¯´æ–‡ä»¶å‘½åä¸º a.txt å¹¶æ”¾åœ¨å½“å‰ç›®å½•")
            return False

        splitter = TextSplitter()
        splitter.split_novel(input_file, "size")
        print("æ–‡æœ¬åˆ†å‰²å®Œæˆï¼")
        return True
    except Exception as e:
        print(f"æ–‡æœ¬åˆ†å‰²å¤±è´¥: {e}")
        return False

def extract_characters():
    """æå–è§’è‰²ä¿¡æ¯"""
    print("å¼€å§‹è§’è‰²æå–...")
    try:
        import asyncio
        from character_extractor_llm import LLMCharacterExtractor
        extractor = LLMCharacterExtractor()
        asyncio.run(extractor.extract_all_characters())
        print("è§’è‰²æå–å®Œæˆï¼")
        return True
    except Exception as e:
        print(f"è§’è‰²æå–å¤±è´¥: {e}")
        return False

def merge_characters():
    """åˆå¹¶è§’è‰²æ•°æ®"""
    print("å¼€å§‹è§’è‰²åˆå¹¶...")
    try:
        from character_merger import CharacterMerger
        merger = CharacterMerger()
        merger.merge_all_characters()
        print("è§’è‰²åˆå¹¶å®Œæˆï¼")
        return True
    except Exception as e:
        print(f"è§’è‰²åˆå¹¶å¤±è´¥: {e}")
        return False

def create_character_cards():
    """åˆ›å»ºè§’è‰²å¡"""
    print("å¼€å§‹åˆ›å»ºè§’è‰²å¡...")
    try:
        import asyncio
        from create_card import CardCreator
        creator = CardCreator()
        asyncio.run(creator.create_all_cards_async())
        print("è§’è‰²å¡åˆ›å»ºå®Œæˆï¼")
        return True
    except Exception as e:
        print(f"è§’è‰²å¡åˆ›å»ºå¤±è´¥: {e}")
        return False

def filter_characters():
    """ç­›é€‰è§’è‰²ï¼Œä¿ç•™å‰50ä¸ªæœ€å¤§çš„æ–‡ä»¶"""
    print("å¼€å§‹ç­›é€‰è§’è‰²...")
    try:
        from character_filter import CharacterFilter
        filter_tool = CharacterFilter()

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        filter_tool.show_statistics()

        # æ‰§è¡Œç­›é€‰
        kept, removed = filter_tool.filter_characters(dry_run=False)

        if removed > 0:
            print(f"[SUCCESS] è§’è‰²ç­›é€‰å®Œæˆï¼ä¿ç•™äº† {kept} ä¸ªæœ€å¤§çš„è§’è‰²æ–‡ä»¶ï¼Œç§»é™¤äº† {removed} ä¸ªè¾ƒå°çš„æ–‡ä»¶")
        else:
            print(f"[SUCCESS] è§’è‰²ç­›é€‰å®Œæˆï¼å½“å‰åªæœ‰ {kept} ä¸ªè§’è‰²æ–‡ä»¶ï¼Œæ— éœ€ç­›é€‰")

        return True
    except Exception as e:
        print(f"è§’è‰²ç­›é€‰å¤±è´¥: {e}")
        return False

def extract_worldbook():
    """æå–ä¸–ç•Œä¹¦æ¡ç›®"""
    print("å¼€å§‹æå–ä¸–ç•Œä¹¦åŸå§‹æ¡ç›®...")
    try:
        import asyncio
        from worldbook_extractor import WorldbookExtractor
        extractor = WorldbookExtractor()
        asyncio.run(extractor.extract_all())
        print("ä¸–ç•Œä¹¦æ¡ç›®æå–å®Œæˆï¼")
        return True
    except Exception as e:
        print(f"ä¸–ç•Œä¹¦æ¡ç›®æå–å¤±è´¥: {e}")
        return False

def generate_worldbook():
    """ç”Ÿæˆç»“æ„åŒ–ä¸–ç•Œä¹¦"""
    print("å¼€å§‹ç”Ÿæˆç»“æ„åŒ–ä¸–ç•Œä¹¦...")
    try:
        import asyncio
        from worldbook_generator import WorldbookGenerator
        from project_config import get_config

        generator = WorldbookGenerator()
        config = get_config()

        # æ£€æŸ¥å¯ç”¨çš„æ¶æ„æ¨¡å¼
        event_mode = config.get('event_driven_architecture.enable', True)
        rules_mode = config.get('world_rules.enable_extraction', True)

        if event_mode and rules_mode:
            print("ğŸ—ï¸ ä½¿ç”¨ä¸‰å±‚æ¶æ„æ¨¡å¼ç”Ÿæˆä¸–ç•Œä¹¦ï¼ˆè§„åˆ™å±‚+æ—¶é—´çº¿å±‚+äº‹ä»¶å±‚ï¼‰...")
            # ä¸‰å±‚æ¶æ„æ¨¡å¼ï¼šéœ€è¦å®ç°å®Œæ•´çš„ä¸‰å±‚ç”Ÿæˆæµç¨‹
            try:
                async def generate_layered():
                    # 1. åŠ è½½è§„åˆ™æ•°æ®
                    rules = generator.load_and_sort_rules()
                    if rules:
                        grouped_rules = generator.aggregate_rules_by_type(rules)
                        rule_summaries = await generator.summarize_rules(grouped_rules)
                    else:
                        rule_summaries = {}

                    # 2. åŠ è½½äº‹ä»¶æ•°æ®å¹¶ç”Ÿæˆæ—¶é—´çº¿å’Œå®ä½“
                    events = generator.load_and_sort_events()
                    if events:
                        timeline_content = await generator.summarize_timeline(events)
                        aggregated_entities = generator.aggregate_entities_from_events(events)
                        entity_summaries = await generator.summarize_entities(aggregated_entities)
                        event_entries = generator.create_event_entries(events)
                    else:
                        timeline_content = "## æ•…äº‹æ—¶é—´çº¿\n\n*æš‚æ— äº‹ä»¶æ•°æ®*"
                        entity_summaries = {}
                        event_entries = []

                    # 3. ç”Ÿæˆä¸‰å±‚ä¸–ç•Œä¹¦
                    output_file = generator.save_layered_worldbook(
                        rule_summaries, timeline_content, entity_summaries, event_entries
                    )
                    print(f"âœ… ä¸‰å±‚æ¶æ„ä¸–ç•Œä¹¦ç”Ÿæˆå®Œæˆ: {output_file}")
                    return output_file

                asyncio.run(generate_layered())

            except Exception as e:
                print(f"âŒ ä¸‰å±‚æ¶æ„æ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°äº‹ä»¶é©±åŠ¨æ¨¡å¼: {e}")
                asyncio.run(generator.generate_timeline_worldbook())

        elif event_mode:
            print("ğŸš€ ä½¿ç”¨äº‹ä»¶é©±åŠ¨æ¨¡å¼ç”Ÿæˆä¸–ç•Œä¹¦...")
            asyncio.run(generator.generate_timeline_worldbook())
        else:
            print("ğŸ“š ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ç”Ÿæˆä¸–ç•Œä¹¦...")
            asyncio.run(generator.generate_worldbook())

        print("ç»“æ„åŒ–ä¸–ç•Œä¹¦ç”Ÿæˆå®Œæˆï¼")

        # è‡ªåŠ¨è½¬æ¢ä¸ºSillyTavern V2æ ¼å¼
        print("\nå¼€å§‹è½¬æ¢ä¸ºSillyTavern V2æ ¼å¼...")
        if convert_worldbook_format():
            print("ä¸–ç•Œä¹¦æ ¼å¼è½¬æ¢å®Œæˆï¼")
        else:
            print("ä¸–ç•Œä¹¦æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½†åŸå§‹ä¸–ç•Œä¹¦å·²ç”Ÿæˆ")

        return True
    except Exception as e:
        print(f"ç»“æ„åŒ–ä¸–ç•Œä¹¦ç”Ÿæˆå¤±è´¥: {e}")
        return False

def convert_worldbook_format():
    """è½¬æ¢ä¸–ç•Œä¹¦ä¸ºSillyTavern V2æ ¼å¼"""
    try:
        from code import WorldbookFormatter
        formatter = WorldbookFormatter("worldbook")
        formatter.convert()
        return True
    except Exception as e:
        print(f"ä¸–ç•Œä¹¦æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
        return False

def clean_worldbook_files():
    """æ¸…ç†ä¸–ç•Œä¹¦ç›¸å…³çš„æ–‡ä»¶å’Œç›®å½•"""
    print("æ¸…ç†ä¸–ç•Œä¹¦ç›¸å…³ç›®å½•...")
    dirs_to_clean = [
        Path("chunks"),           # æ·»åŠ chunksç›®å½•æ¸…ç†
        Path("wb_responses"),
        Path("wb_raw_responses"),
        Path("wb_bad_chunks"),
        Path("worldbook")
    ]
    for dir_path in dirs_to_clean:
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                print(f"å·²åˆ é™¤ç›®å½•: {dir_path}")
            except Exception as e:
                print(f"åˆ é™¤ç›®å½•å¤±è´¥ {dir_path}: {e}")
    print("ä¸–ç•Œä¹¦ç›®å½•æ¸…ç†å®Œæˆï¼")

def run_wb_auto_workflow():
    """è¿è¡Œä¸€é”®å…¨è‡ªåŠ¨ä¸–ç•Œä¹¦ç”Ÿæˆæµç¨‹"""
    print("="*60)
    print("å¼€å§‹æ‰§è¡Œä¸€é”®å…¨è‡ªåŠ¨ä¸–ç•Œä¹¦ç”Ÿæˆæµç¨‹")
    print("="*60)

    # æ­¥éª¤0: æ¸…ç†ä¸–ç•Œä¹¦ç›¸å…³ç›®å½•
    print("\næ­¥éª¤0: æ¸…ç†ä¸–ç•Œä¹¦ç›¸å…³ç›®å½•")
    clean_worldbook_files()

    # æ­¥éª¤1: åˆ†å‰²æ–‡æœ¬ï¼ˆå¼ºåˆ¶é‡æ–°åˆ†å‰²ï¼‰
    print("\næ­¥éª¤1: åˆ†å‰²å°è¯´æ–‡æœ¬")
    if not split_text():
        print("å·¥ä½œæµä¸­æ–­ï¼šæ–‡æœ¬åˆ†å‰²å¤±è´¥")
        return

    # æ­¥éª¤2: æå–ä¸–ç•Œä¹¦æ¡ç›®
    print("\næ­¥éª¤2: æå–ä¸–ç•Œä¹¦åŸå§‹æ¡ç›®")
    if not extract_worldbook():
        print("å·¥ä½œæµä¸­æ–­ï¼šä¸–ç•Œä¹¦æå–å¤±è´¥")
        return

    # æ­¥éª¤3: ç”Ÿæˆç»“æ„åŒ–ä¸–ç•Œä¹¦
    print("\næ­¥éª¤3: ç”Ÿæˆç»“æ„åŒ–ä¸–ç•Œä¹¦")
    if not generate_worldbook():
        print("å·¥ä½œæµä¸­æ–­ï¼šä¸–ç•Œä¹¦ç”Ÿæˆå¤±è´¥")
        return

    print("\n="*60)
    print("ä¸–ç•Œä¹¦å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
    print("="*60)

    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    show_wb_final_stats()

def show_wb_final_stats():
    """æ˜¾ç¤ºä¸–ç•Œä¹¦æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
    print("\nä¸–ç•Œä¹¦ç»Ÿè®¡:")

    # ç»Ÿè®¡å„é˜¶æ®µçš„æ–‡ä»¶æ•°é‡
    chunks_count = len(list(Path("chunks").glob("chunk_*.txt"))) if Path("chunks").exists() else 0
    wb_extracted_count = len(list(Path("wb_responses").glob("*.json"))) if Path("wb_responses").exists() else 0
    worldbook_files = len(list(Path("worldbook").glob("*.json"))) if Path("worldbook").exists() else 0

    print(f"  æ–‡æœ¬åˆ†å—: {chunks_count} ä¸ª")
    print(f"  æå–æ¡ç›®: {wb_extracted_count} ä¸ªæ–‡ä»¶")
    print(f"  ç”Ÿæˆä¸–ç•Œä¹¦: {worldbook_files} ä¸ªæ–‡ä»¶")

    # ç»Ÿè®¡æ€»æ¡ç›®æ•°
    total_entries = 0
    if Path("wb_responses").exists():
        for wb_file in Path("wb_responses").glob("*.json"):
            try:
                with open(wb_file, 'r', encoding='utf-8') as f:
                    import json
                    data = json.load(f)
                    if isinstance(data, list):
                        total_entries += len(data)
            except:
                pass

    print(f"  æ€»æå–æ¡ç›®: {total_entries} ä¸ª")

    if Path("worldbook").exists():
        print(f"  è¾“å‡ºä½ç½®: worldbook/ ç›®å½•")

def run_auto_workflow():
    """è¿è¡Œä¸€é”®å…¨è‡ªåŠ¨å·¥ä½œæµ"""
    print("="*60)
    print("å¼€å§‹æ‰§è¡Œä¸€é”®å…¨è‡ªåŠ¨åˆ¶å¡æµç¨‹")
    print("="*60)

    # æ­¥éª¤0: æ¸…ç†
    print("\næ­¥éª¤0: æ¸…ç†æ—§æ–‡ä»¶å’Œç›®å½•")
    clean_all()

    # è¿è¡Œå®Œæ•´å·¥ä½œæµ
    run_full_workflow()

def clean_all():
    """æ¸…ç†æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶å’Œç›®å½•"""
    print("æ¸…ç†æ‰€æœ‰ä¸­é—´ç›®å½•å’Œè¾“å‡ºç›®å½•...")
    dirs_to_clean = [
        Path("chunks"),
        Path("character_responses"),
        Path("roles_json"),
        Path("cards")
    ]
    for dir_path in dirs_to_clean:
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                print(f"å·²åˆ é™¤ç›®å½•: {dir_path}")
            except Exception as e:
                print(f"åˆ é™¤ç›®å½•å¤±è´¥ {dir_path}: {e}")
    print("æ¸…ç†å®Œæˆï¼")

def run_full_workflow():
    """è¿è¡Œå®Œæ•´å·¥ä½œæµ"""
    print("="*60)
    print("å¼€å§‹æ‰§è¡Œå®Œæ•´è§’è‰²å·¥ä½œæµ")
    print("="*60)

    # æ­¥éª¤0: åˆ†å‰²æ–‡æœ¬
    print("\næ­¥éª¤0: åˆ†å‰²å°è¯´æ–‡æœ¬")
    if not split_text():
        print("å·¥ä½œæµä¸­æ–­ï¼šæ–‡æœ¬åˆ†å‰²å¤±è´¥")
        return False

    # æ­¥éª¤1: æå–è§’è‰²
    print("\næ­¥éª¤1: ä»æ–‡æœ¬å—æå–è§’è‰²ä¿¡æ¯")
    if not extract_characters():
        print("å·¥ä½œæµä¸­æ–­ï¼šè§’è‰²æå–å¤±è´¥")
        return False

    # æ­¥éª¤2: åˆå¹¶è§’è‰²
    print("\næ­¥éª¤2: åˆå¹¶é‡å¤è§’è‰²æ•°æ®")
    if not merge_characters():
        print("å·¥ä½œæµä¸­æ–­ï¼šè§’è‰²åˆå¹¶å¤±è´¥")
        return False

    # æ­¥éª¤3: ç­›é€‰è§’è‰²
    print("\næ­¥éª¤3: ç­›é€‰è§’è‰²ï¼Œä¿ç•™å‰50ä¸ªæœ€å¤§çš„æ–‡ä»¶")
    if not filter_characters():
        print("å·¥ä½œæµä¸­æ–­ï¼šè§’è‰²ç­›é€‰å¤±è´¥")
        return False

    # æ­¥éª¤4: åˆ›å»ºè§’è‰²å¡
    print("\næ­¥éª¤4: ç”Ÿæˆè§’è‰²å¡")
    if not create_character_cards():
        print("å·¥ä½œæµä¸­æ–­ï¼šè§’è‰²å¡åˆ›å»ºå¤±è´¥")
        return False

    print("\n="*60)
    print("å®Œæ•´è§’è‰²å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
    print("="*60)

    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    show_final_stats()
    return True

def show_final_stats():
    """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
    print("\næœ€ç»ˆç»Ÿè®¡:")
    
    # ç»Ÿè®¡å„é˜¶æ®µçš„æ–‡ä»¶æ•°é‡
    chunks_count = len(list(Path("chunks").glob("chunk_*.txt"))) if Path("chunks").exists() else 0
    extracted_count = len(list(Path("character_responses").glob("*.json"))) if Path("character_responses").exists() else 0
    merged_count = len([f for f in Path("roles_json").glob("*.json") if f.name != "character_stats.json"]) if Path("roles_json").exists() else 0
    cards_count = len(list(Path("cards").glob("*.json"))) if Path("cards").exists() else 0
    
    print(f"  æ–‡æœ¬åˆ†å—: {chunks_count} ä¸ª")
    print(f"  æå–è§’è‰²: {extracted_count} ä¸ª")
    print(f"  åˆå¹¶è§’è‰²: {merged_count} ä¸ª")
    print(f"  è§’è‰²å¡: {cards_count} ä¸ª")
    
    # è®¡ç®—å¤„ç†æ•ˆç‡
    if chunks_count > 0 and merged_count > 0:
        efficiency = merged_count / chunks_count
        print(f"  å¤„ç†æ•ˆç‡: æ¯ä¸ªæ–‡æœ¬å—å¹³å‡æå– {efficiency:.2f} ä¸ªè§’è‰²")

def clean_intermediate_files():
    """æ¸…ç†ä¸­é—´æ–‡ä»¶"""
    print("æ¸…ç†ä¸­é—´æ–‡ä»¶...")
    
    # æ¸…ç†character_responsesç›®å½•
    responses_dir = Path("character_responses")
    if responses_dir.exists():
        for file in responses_dir.glob("*.json"):
            file.unlink()
            print(f"åˆ é™¤: {file}")
        
        # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
        try:
            responses_dir.rmdir()
            print(f"åˆ é™¤ç›®å½•: {responses_dir}")
        except:
            pass
    
    print("ä¸­é—´æ–‡ä»¶æ¸…ç†å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        show_help()
        return
    
    command = sys.argv[1].lower()

    if command == "auto":
        # ä¸€é”®å…¨è‡ªåŠ¨
        run_auto_workflow()

    elif command == "split":
        # åˆ†å‰²æ–‡æœ¬
        split_text()

    elif command == "extract":
        # æå–è§’è‰²
        extract_characters()

    elif command == "merge":
        # åˆå¹¶è§’è‰²
        merge_characters()

    elif command == "filter":
        # ç­›é€‰è§’è‰²
        filter_characters()

    elif command == "full":
        # å®Œæ•´æµç¨‹
        run_full_workflow()

    elif command == "create":
        # åˆ›å»ºè§’è‰²å¡
        create_character_cards()

    elif command == "wb-extract":
        # æå–ä¸–ç•Œä¹¦
        extract_worldbook()

    elif command == "wb-generate":
        # ç”Ÿæˆä¸–ç•Œä¹¦
        generate_worldbook()

    elif command == "wb-auto":
        # ä¸€é”®ç”Ÿæˆä¸–ç•Œä¹¦
        run_wb_auto_workflow()

    elif command == "status":
        # æ˜¾ç¤ºçŠ¶æ€
        show_status()

    elif command == "clean":
        # æ¸…ç†æ–‡ä»¶
        clean_all()

    elif command == "help":
        # æ˜¾ç¤ºå¸®åŠ©
        show_help()

    else:
        print(f"æœªçŸ¥å‘½ä»¤: {command}")
        show_help()

if __name__ == "__main__":
    main()
